#!/usr/bin/env python3
"""
Generate PowerPoint presentation for Xsentiment project
Requires: pip install python-pptx
"""

from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.dml.color import RGBColor
from pptx.enum.text import PP_ALIGN

def create_xsentiment_presentation():
    """Create a comprehensive PowerPoint presentation for Xsentiment"""
    
    # Create presentation object
    prs = Presentation()
    
    # Define color scheme
    primary_color = RGBColor(29, 161, 242)  # Twitter blue
    secondary_color = RGBColor(47, 79, 79)  # Dark slate gray
    accent_color = RGBColor(255, 107, 107)  # Light red
    
    # Slide 1: Title Slide
    slide_layout = prs.slide_layouts[0]  # Title slide layout
    slide = prs.slides.add_slide(slide_layout)
    
    title = slide.shapes.title
    subtitle = slide.placeholders[1]
    
    title.text = "ðŸ¦ Xsentiment"
    subtitle.text = "Twitter Sentiment Analysis Tool\n\nReal-time Tweet Collection & Analysis\nComprehensive Visualization Dashboard"
    
    # Format title
    title_para = title.text_frame.paragraphs[0]
    title_para.font.size = Pt(44)
    title_para.font.color.rgb = primary_color
    
    # Format subtitle
    subtitle_para = subtitle.text_frame.paragraphs[0]
    subtitle_para.font.size = Pt(20)
    subtitle_para.font.color.rgb = secondary_color
    
    # Slide 2: Project Overview
    slide_layout = prs.slide_layouts[1]  # Title and content layout
    slide = prs.slides.add_slide(slide_layout)
    
    title = slide.shapes.title
    content = slide.placeholders[1]
    
    title.text = "ðŸ“Š Project Overview"
    content.text = """Purpose: Comprehensive Twitter sentiment analysis solution

Key Objectives:
â€¢ Monitor public opinion in real-time
â€¢ Classify tweet sentiment automatically
â€¢ Generate actionable insights through visualizations
â€¢ Support research and business intelligence

Target Audience:
â€¢ Social media analysts
â€¢ Market researchers
â€¢ Academic researchers
â€¢ Business intelligence teams"""
    
    # Slide 3: System Architecture
    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    
    title = slide.shapes.title
    content = slide.placeholders[1]
    
    title.text = "ðŸ—ï¸ System Architecture"
    content.text = """Data Flow Pipeline:

1. Data Collection Layer
   â€¢ Twitter API v2 integration
   â€¢ Real-time tweet streaming
   â€¢ Keyword-based filtering

2. Processing Layer
   â€¢ TextBlob sentiment analysis
   â€¢ Duplicate detection & removal
   â€¢ Data cleaning & preprocessing

3. Storage Layer
   â€¢ CSV-based data persistence
   â€¢ Timestamp tracking
   â€¢ Incremental data updates

4. Visualization Layer
   â€¢ Multiple chart types
   â€¢ Interactive dashboards
   â€¢ Export capabilities"""
    
    # Slide 4: Technical Features
    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    
    title = slide.shapes.title
    content = slide.placeholders[1]
    
    title.text = "âš¡ Technical Features"
    content.text = """Core Capabilities:

ðŸ”„ Continuous Operation
â€¢ Runs indefinitely until interrupted
â€¢ 5-minute collection cycles
â€¢ Automatic rate limit handling

ðŸ§  Sentiment Analysis
â€¢ TextBlob polarity scoring
â€¢ Three-class classification (Positive/Negative/Neutral)
â€¢ English language filtering

ðŸ“Š Advanced Visualizations
â€¢ Static charts (PNG): Pie, Bar, Timeline
â€¢ Word clouds by sentiment
â€¢ Interactive Plotly dashboards
â€¢ Real-time data updates

ðŸ›¡ï¸ Robust Error Handling
â€¢ API rate limit management
â€¢ Graceful shutdown on interruption
â€¢ Comprehensive logging"""
    
    # Slide 5: Key Components
    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    
    title = slide.shapes.title
    content = slide.placeholders[1]
    
    title.text = "ðŸ”§ Key Components"
    content.text = """Main Scripts:

ðŸ“„ script.py (Data Collection Engine)
â€¢ Twitter API integration with Tweepy
â€¢ Continuous tweet collection
â€¢ Real-time sentiment analysis
â€¢ CSV data persistence
â€¢ Duplicate prevention

ðŸ“„ visualize_tweets.py (Visualization Engine)
â€¢ Multiple chart types generation
â€¢ Interactive dashboard creation
â€¢ Word cloud generation
â€¢ Timeline analysis
â€¢ Statistical summaries

ðŸ“„ requirements_viz.txt
â€¢ All necessary Python dependencies
â€¢ Visualization libraries (Matplotlib, Plotly, Seaborn)
â€¢ Data processing tools (Pandas, NumPy)"""
    
    # Slide 6: Methodology
    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    
    title = slide.shapes.title
    content = slide.placeholders[1]
    
    title.text = "ðŸ”¬ Methodology"
    content.text = """Step-by-Step Process:

1ï¸âƒ£ Data Collection
   â€¢ Connect to Twitter API v2
   â€¢ Search recent tweets by keyword
   â€¢ Filter English-language tweets only
   â€¢ Handle pagination for large datasets

2ï¸âƒ£ Sentiment Analysis
   â€¢ Apply TextBlob sentiment polarity
   â€¢ Convert polarity to categorical labels:
     - Positive: polarity > 0
     - Negative: polarity < 0
     - Neutral: polarity = 0

3ï¸âƒ£ Data Storage
   â€¢ Append new tweets to CSV
   â€¢ Remove duplicates based on text
   â€¢ Add collection timestamps
   â€¢ Maintain data integrity

4ï¸âƒ£ Visualization & Analysis
   â€¢ Generate multiple chart types
   â€¢ Create interactive dashboards
   â€¢ Provide statistical summaries"""
    
    # Slide 7: Usage Instructions
    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    
    title = slide.shapes.title
    content = slide.placeholders[1]
    
    title.text = "ðŸš€ How to Use"
    content.text = """Setup & Configuration:

1. Prerequisites
   â€¢ Python 3.9+
   â€¢ Twitter Developer Account
   â€¢ API Bearer Token

2. Installation
   pip3 install tweepy textblob pandas
   pip3 install -r requirements_viz.txt

3. Configuration
   â€¢ Update BEARER_TOKEN in script.py
   â€¢ Modify KEYWORD for target search terms
   â€¢ Adjust MAX_RESULTS and SLEEP_INTERVAL

4. Execution
   # Start data collection
   python3 script.py
   
   # Generate visualizations
   python3 visualize_tweets.py

5. Stop Collection
   â€¢ Press Ctrl+C for graceful shutdown"""
    
    # Slide 8: Visualization Types
    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    
    title = slide.shapes.title
    content = slide.placeholders[1]
    
    title.text = "ðŸ“ˆ Visualization Types"
    content.text = """Available Chart Types:

ðŸ¥§ Pie Charts
â€¢ Sentiment distribution percentages
â€¢ Color-coded by sentiment type
â€¢ Clear percentage labels

ðŸ“Š Bar Charts
â€¢ Tweet counts by sentiment
â€¢ Value labels on bars
â€¢ Professional styling

ðŸ“… Timeline Charts
â€¢ Sentiment trends over time
â€¢ Multi-line plots for each sentiment
â€¢ Date-based analysis

â˜ï¸ Word Clouds
â€¢ Most common words by sentiment
â€¢ Filtered stop words
â€¢ Visual word frequency representation

ðŸŽ›ï¸ Interactive Dashboard
â€¢ Multi-panel Plotly interface
â€¢ Hover effects and zoom
â€¢ Tweet length distribution
â€¢ Top words analysis"""
    
    # Slide 9: Configuration Options
    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    
    title = slide.shapes.title
    content = slide.placeholders[1]
    
    title.text = "âš™ï¸ Configuration Options"
    content.text = """Customizable Parameters:

ðŸ” Search Configuration
KEYWORD = "OpenAI"           # Target search terms
MAX_RESULTS = 10             # Tweets per cycle
SLEEP_INTERVAL = 300         # Seconds between cycles

ðŸ“ Advanced Search Examples
â€¢ Single term: "ChatGPT"
â€¢ Multiple terms: "AI OR ML OR DeepLearning"
â€¢ Hashtags: "#MachineLearning"
â€¢ Complex queries: "OpenAI AND (GPT OR ChatGPT)"

â° Rate Limit Management
â€¢ Twitter API v2: 300 requests/15 minutes
â€¢ Built-in wait_on_rate_limit handling
â€¢ Configurable sleep intervals
â€¢ Automatic retry mechanism

ðŸ’¾ Data Management
â€¢ CSV file location: tweets_sentiment.csv
â€¢ Automatic backup and duplicate removal
â€¢ Timestamped data collection
â€¢ Long-term data persistence"""
    
    # Slide 10: Sample Output
    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    
    title = slide.shapes.title
    content = slide.placeholders[1]
    
    title.text = "ðŸ“‹ Sample Output"
    content.text = """Example Dataset Summary:

==================================================
DATASET SUMMARY
==================================================
Total tweets: 150
Columns: ['Text', 'Sentiment', 'Created_At', 'Collection_Time']

Sentiment Distribution:
  Positive: 89 (59.3%)
  Neutral: 45 (30.0%)
  Negative: 16 (10.7%)

Date range: 2025-06-14 to 2025-06-15

Sample tweets:
  [Positive] Amazing progress in AI development...
  [Neutral] New AI paper released today...
  [Negative] Concerns about AI safety..."""
    
    # Slide 11: Use Cases & Applications
    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    
    title = slide.shapes.title
    content = slide.placeholders[1]
    
    title.text = "ðŸŽ¯ Use Cases & Applications"
    content.text = """Real-World Applications:

ðŸ¢ Business Intelligence
â€¢ Brand sentiment monitoring
â€¢ Product launch feedback analysis
â€¢ Competitor sentiment tracking
â€¢ Crisis management response

ðŸŽ“ Academic Research
â€¢ Public opinion studies
â€¢ Social media behavior analysis
â€¢ Political sentiment research
â€¢ Event impact assessment

ðŸ“ˆ Marketing & PR
â€¢ Campaign effectiveness measurement
â€¢ Influencer impact analysis
â€¢ Trend identification
â€¢ Audience sentiment profiling

ðŸ” Market Research
â€¢ Consumer opinion analysis
â€¢ Product feedback collection
â€¢ Market trend identification
â€¢ Customer satisfaction monitoring"""
    
    # Slide 12: Technical Specifications
    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    
    title = slide.shapes.title
    content = slide.placeholders[1]
    
    title.text = "ðŸ”§ Technical Specifications"
    content.text = """System Requirements:

ðŸ’» Environment
â€¢ Python 3.9+
â€¢ macOS/Linux/Windows compatible
â€¢ Internet connection required

ðŸ“š Dependencies
Core Libraries:
â€¢ tweepy (Twitter API)
â€¢ textblob (Sentiment analysis)
â€¢ pandas (Data manipulation)

Visualization Libraries:
â€¢ matplotlib (Static plots)
â€¢ seaborn (Statistical plots)
â€¢ plotly (Interactive dashboards)
â€¢ wordcloud (Word cloud generation)

ðŸ” API Requirements
â€¢ Twitter Developer Account
â€¢ Bearer Token for API v2 access
â€¢ Rate limits: 300 requests/15 minutes

ðŸ’¾ Storage
â€¢ CSV format for data persistence
â€¢ Automatic file management
â€¢ Incremental data updates"""
    
    # Slide 13: Security & Best Practices
    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    
    title = slide.shapes.title
    content = slide.placeholders[1]
    
    title.text = "ðŸ”’ Security & Best Practices"
    content.text = """Security Considerations:

ðŸ”‘ API Key Management
â€¢ Never commit API keys to version control
â€¢ Use environment variables for credentials
â€¢ Implement secure key rotation practices

ðŸ’¡ Recommended Setup
import os
BEARER_TOKEN = os.getenv('TWITTER_BEARER_TOKEN')

ðŸ“ Data Protection
â€¢ .gitignore includes sensitive data files
â€¢ Local CSV storage only
â€¢ No cloud upload by default

âš¡ Performance Optimization
â€¢ Respect API rate limits
â€¢ Implement efficient caching
â€¢ Use appropriate sleep intervals
â€¢ Monitor resource usage

ðŸ›¡ï¸ Error Handling
â€¢ Graceful shutdown on interrupts
â€¢ Comprehensive logging
â€¢ Automatic retry mechanisms
â€¢ Data integrity validation"""
    
    # Slide 14: Future Enhancements
    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    
    title = slide.shapes.title
    content = slide.placeholders[1]
    
    title.text = "ðŸ”® Future Enhancements"
    content.text = """Potential Improvements:

ðŸ¤– Advanced Analytics
â€¢ Machine learning-based sentiment analysis
â€¢ Emotion detection (joy, anger, fear, etc.)
â€¢ Sarcasm and context awareness
â€¢ Multi-language support

â˜ï¸ Cloud Integration
â€¢ Real-time streaming with Apache Kafka
â€¢ Cloud database storage (PostgreSQL, MongoDB)
â€¢ Scalable processing with Apache Spark
â€¢ Docker containerization

ðŸŒ Web Dashboard
â€¢ Real-time web interface
â€¢ User authentication system
â€¢ Multi-user support
â€¢ Custom alert notifications

ðŸ“± Mobile Application
â€¢ iOS/Android companion apps
â€¢ Push notifications for trends
â€¢ Mobile-friendly visualizations
â€¢ Offline data viewing

ðŸ”§ Additional Features
â€¢ Influencer identification
â€¢ Hashtag trend analysis
â€¢ Geographic sentiment mapping
â€¢ Competitive analysis tools"""
    
    # Slide 15: Benefits & Impact
    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    
    title = slide.shapes.title
    content = slide.placeholders[1]
    
    title.text = "ðŸ’¡ Benefits & Impact"
    content.text = """Project Value Proposition:

âœ… Cost-Effective Solution
â€¢ Open-source implementation
â€¢ No licensing fees
â€¢ Scalable architecture
â€¢ Minimal infrastructure requirements

ðŸ“Š Data-Driven Insights
â€¢ Real-time sentiment tracking
â€¢ Historical trend analysis
â€¢ Quantitative opinion measurement
â€¢ Evidence-based decision making

ðŸš€ Easy Implementation
â€¢ Simple setup process
â€¢ Comprehensive documentation
â€¢ Modular design
â€¢ Extensible architecture

ðŸŽ¯ Immediate Business Value
â€¢ Brand reputation monitoring
â€¢ Customer feedback analysis
â€¢ Market trend identification
â€¢ Crisis detection and response

ðŸ”¬ Research Applications
â€¢ Academic research support
â€¢ Social media behavior studies
â€¢ Public opinion analysis
â€¢ Policy impact assessment"""
    
    # Slide 16: Demo & Screenshots
    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    
    title = slide.shapes.title
    content = slide.placeholders[1]
    
    title.text = "ðŸ“¸ Generated Visualizations"
    content.text = """Sample Output Files:

ðŸ“Š Static Charts (PNG Format)
â€¢ sentiment_pie_chart.png
  - Circular representation of sentiment distribution
  - Percentage labels for each category
  - Color-coded segments

â€¢ sentiment_bar_chart.png
  - Bar chart with tweet counts
  - Value labels on each bar
  - Professional styling

â€¢ sentiment_timeline.png
  - Time-series analysis
  - Multi-line plot for trends
  - Date-based insights

â˜ï¸ Word Clouds
â€¢ wordcloud_positive.png
â€¢ wordcloud_negative.png
â€¢ wordcloud_neutral.png

ðŸŒ Interactive Dashboard
â€¢ tweet_dashboard.html
  - Multi-panel interface
  - Interactive hover effects
  - Zoomable charts"""
    
    # Slide 17: Conclusion
    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    
    title = slide.shapes.title
    content = slide.placeholders[1]
    
    title.text = "ðŸŽ‰ Conclusion"
    content.text = """Project Summary:

âœ¨ What We Accomplished
â€¢ Built a comprehensive Twitter sentiment analysis tool
â€¢ Implemented real-time data collection and processing
â€¢ Created multiple visualization options
â€¢ Designed a user-friendly, extensible system

ðŸŽ¯ Key Strengths
â€¢ Real-time sentiment monitoring capabilities
â€¢ Professional visualization outputs
â€¢ Robust error handling and rate limit management
â€¢ Comprehensive documentation and setup instructions

ðŸŒŸ Value Delivered
â€¢ Actionable insights from social media data
â€¢ Cost-effective alternative to commercial tools
â€¢ Educational resource for sentiment analysis
â€¢ Foundation for advanced analytics projects

ðŸš€ Ready for Production
â€¢ Thoroughly tested components
â€¢ Scalable architecture
â€¢ Professional-grade visualizations
â€¢ Enterprise-ready documentation"""
    
    # Slide 18: Questions & Contact
    slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(slide_layout)
    
    title = slide.shapes.title
    content = slide.placeholders[1]
    
    title.text = "â“ Questions & Discussion"
    content.text = """Thank you for your attention!

ðŸ¤ Let's Discuss
â€¢ Implementation questions
â€¢ Technical challenges
â€¢ Use case scenarios
â€¢ Future enhancement ideas

ðŸ“§ Get Started
1. Clone the repository
2. Install dependencies
3. Configure Twitter API
4. Run your first analysis

ðŸ”— Resources
â€¢ GitHub repository with full source code
â€¢ Comprehensive README documentation
â€¢ Installation and setup guides
â€¢ Example configurations

ðŸ’¬ Open Floor
â€¢ Questions about implementation?
â€¢ Interested in specific use cases?
â€¢ Want to discuss enhancements?
â€¢ Need help with setup?

Thank you! ðŸ¦ðŸ“Šâœ¨"""
    
    # Save presentation
    prs.save('Xsentiment_Comprehensive_Presentation.pptx')
    print("âœ… PowerPoint presentation created successfully!")
    print("ðŸ“„ File saved as: Xsentiment_Comprehensive_Presentation.pptx")
    print("\nðŸ“Š Presentation contains 18 comprehensive slides:")
    print("   1. Title Slide")
    print("   2. Project Overview")
    print("   3. System Architecture")
    print("   4. Technical Features")
    print("   5. Key Components")
    print("   6. Methodology")
    print("   7. Usage Instructions")
    print("   8. Visualization Types")
    print("   9. Configuration Options")
    print("   10. Sample Output")
    print("   11. Use Cases & Applications")
    print("   12. Technical Specifications")
    print("   13. Security & Best Practices")
    print("   14. Future Enhancements")
    print("   15. Benefits & Impact")
    print("   16. Demo & Screenshots")
    print("   17. Conclusion")
    print("   18. Questions & Contact")

if __name__ == "__main__":
    try:
        create_xsentiment_presentation()
    except ImportError:
        print("âŒ python-pptx not installed!")
        print("ðŸ“¦ Please install it with: pip install python-pptx")
        print("ðŸ”„ Then run this script again.")
    except Exception as e:
        print(f"âŒ Error creating presentation: {e}")
        print("ðŸ› ï¸ Please check the error and try again.")
